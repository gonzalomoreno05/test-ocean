{"cells":[{"metadata":{"_uuid":"60820789-aa12-41c7-8648-fd171d73f098","_cell_guid":"371e3614-7d55-42dc-8dbe-c81f29fbbc5b","trusted":true},"cell_type":"code","source":"# %% [code]\n### This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\n\nfrom sklearn.metrics import mean_squared_error, f1_score, confusion_matrix\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\ndata_path = os.path.join(dirname, filename)\n\ndataset = pd.read_csv(data_path, index_col = 0)\n\n\n# %% [code]\nfeatures = ['title', 'location', 'department', 'salary_range', 'company_profile', 'description', 'requirements', 'benefits', 'telecommuting', 'has_company_logo', 'has_questions', 'employment_type', 'required_experience', 'required_education', 'industry', 'function']\nbool_features = ['telecommuting', 'has_company_logo', 'has_questions']\ntext_features = [ 'title','company_profile', 'description', 'requirements', 'benefits']\ncat_features = ['employment_type', 'required_experience','required_education', 'industry', 'function']\ncat_features_encode = ['employment_type_encode', 'required_experience_encode', 'required_education_encode', 'industry_encode', 'function_encode']\ncat_extra_features = ['salary_min', 'salary_max', 'department']\n\n\n# %% [code]\nprint(dataset)\n\n# %% [code]\ndel dataset\n\n\n# %% [code]\n\"\"\" Missing values\"\"\"\nprint(dataset.isnull().sum())\n\nfor col in cat_features:\n    dataset[col] = dataset[col].fillna('Unknown')   \n\nfor col in text_features:\n    dataset[col] = dataset[col].fillna('')  \n\ndataset['department'].fillna('Unknown')\ndefecto = -1\nsalarios = dataset['salary_range']\nprint(dataset)\nprint(salarios)\n\n#print(dataset.salary_range.unique())\n\n\"\"\" Como los salarios tienen diferentes rangos pero alguno de ellos contiene valores no apropiados, como Apr, Dec, etc. dividimos los rangos en dos columnas para poder analizarlos como contenido numerico y eliminar los contenidos no numericos\"\"\"\n\n\nsalarios = dataset['salary_range'].str.split(\"-\", n = 1, expand = True) \ndataset.drop('salary_range', axis = 1, inplace = True)\ndataset['salary_min'] = salarios[0]\ndataset['salary_max'] = salarios[1]\n    \n\n\"\"\" Rellenamos los espacios nulos con -1\"\"\"\ndataset['salary_min'].fillna(defecto, inplace = True)\ndataset['salary_max'].fillna(defecto, inplace = True)\n\n\n\n\n\nprint(dataset.isnull().sum())\nprint(dataset)\nprint(dataset.groupby('salary_min').sum())\nprint(dataset.groupby('salary_max').sum())\n\n# %% [code]\n\"\"\" Sustituimos los valores no numericos por -1\"\"\"\nmeses = ['Dec', 'Jun', 'Oct', 'Sep', 'Nov', 'Apr']\n            \nfor row in dataset.index:\n    for col in meses:\n        if(dataset['salary_min'][row] == col):\n            dataset['salary_min'][row] = -1\n        \n        if(dataset['salary_max'][row] == col):\n            dataset['salary_max'][row] = -1\n\nprint(dataset.groupby('salary_min').sum())     \nprint(dataset.groupby('salary_max').sum())  \n\n# %% [code]\n\n\n\nfig = plt.figure(figsize = (5,5))\nax = sns.countplot(x = dataset.fraudulent, data = dataset, palette = 'Set1')\nplt.title('fraudulent distribution', fontsize = 15)\nyes = (dataset.fraudulent.value_counts()[1]/dataset.fraudulent.count()) * 100\nno = (dataset.fraudulent.value_counts()[0]/dataset.fraudulent.count()) * 100\n\nrects = ax.patches\n\n# Now make some labels\nlabels = [no, yes]\n\nfor rect, label in zip(rects, labels):\n   height = rect.get_height()\n   ax.text(rect.get_x() + rect.get_width()/2, height + 5,  '{:1.2f}%'.format(label), ha='center', va='bottom', fontsize = 12)\n\n\n\n# %% [code]\nplt.figure(figsize=(20,20))\n\n#sns.countplot(x=dataset., data=dataset[bool_features], hue='fraudulent', palette='Set2')\n# loop to get column and the count of plots\ngrid = gridspec.GridSpec(3, 3, wspace=0.5, hspace=0.5)\n\nfor i, col in enumerate(dataset[bool_features]): \n    fig = plt.subplot(grid[i]) # feeding the figure of grid\n    sns.countplot(x=col, data=dataset, hue='fraudulent', palette = 'Accent')\n    fig.set_title(f'{col} distribution') # title label\n    fig.set_xlabel(f'{col} values') # x axis label\n    fig.set_ylabel('Count') # y axis label\n    plt.legend()\n    #plt.xticks(rotation=90) \n    total = len(dataset)\n    sizes=[] # Get highest values in y\n    for p in fig.patches: # loop to all objects\n        height = p.get_height()\n        sizes.append(height)\n        fig.text(p.get_x() + p.get_width()/2.,\n                height + 3,\n                '{:1.2f}%'.format(height/total*100),\n                ha=\"center\") \n    fig.set_ylim(0, max(sizes) * 1.15) #set y limit based on highest heights\nplt.show()\n\n\n# %% [code]\nplt.figure(figsize = (70,400))\ngrid = gridspec.GridSpec(3, 3, wspace = 1, hspace = 1)\n\nfor i, col in enumerate(dataset[cat_features]): \n    fig = plt.subplot(5,1,i+1,autoscale_on = True) # feeding the figure of grid\n    fig.grid(i)\n    sns.countplot(x = col, data = dataset, hue = 'fraudulent', palette = 'Set1')\n    fig.set_title(f'{col} distribution', fontsize = 40) # title label\n    fig.set_xlabel(f'{col} values', fontsize = 40) # x axis label\n    fig.set_ylabel('Count', fontsize = 40) # y axis label\n    plt.legend(fontsize = 40)\n    fig.tick_params(labelsize = 35, labelrotation = 90)\n    total = len(dataset)\n    sizes = [] # Get highest values in y\n    if (col == 'employment_type' or col == 'required_experience' or col == 'required_education'):\n        for p in fig.patches: # loop to all objects\n            height = p.get_height()\n            sizes.append(height)\n            fig.text(p.get_x() + p.get_width()/2.,\n                    height + 3,\n                    '{:1.2f}%'.format(height / total * 100),\n                    ha = \"center\", fontsize = 40) \n        fig.set_ylim(0, max(sizes) * 1.15) #set y limit based on highest heights\n    \nplt.show()\n#print(dataset.groupby('function').sum())\n#print(dataset.groupby('salary_max').sum())\n#print(dataset.groupby('has_questions').sum())\n#print(dataset.groupby('telecommuting').sum())\n#sns.barplot(x=x_train.telecommuting, y = y_train)\n#sns.barplot(x = x_train.has_questions, y = y_train)\n#print(dataset.groupby('required_education').sum())\n#print(dataset.groupby('has_company_logo').sum())\n\n#sns.heatmap(data = dataset)\n\n\n# %% [code]\n\"\"\" Vamos a analizar el numero de palabras en las diferentes columnas de texto y su posible relaci√≥n con las ofertas fraudulentas \"\"\"\n\nfor i, col in enumerate(text_features):\n    fig, (ax, ay) = plt.subplots(ncols = 2,figsize = (10,4), dpi = 100)\n    fig.tight_layout(pad = 4)\n    palabras = dataset[dataset.fraudulent == 1][col].str.split().map(lambda num: len(num))\n    palabras2 = dataset[dataset.fraudulent == 0][col].str.split().map(lambda num: len(num))\n    \n    ax.hist(x = palabras, bins = 20, color = 'teal')\n    ax.set_title(f'{col} number of words in real offers', fontsize = 10)\n    ax.set_xlabel('number of words', fontsize = 10)\n    ax.set_ylabel('words count', fontsize = 10)\n    ax.tick_params(labelsize = 10)\n    \n    ay.hist(x = palabras2, bins = 20, color = 'olive')   \n    ay.set_title(f'{col} number of words in fake offers', fontsize = 10)\n    ay.set_xlabel('number of words', fontsize = 10)\n    ay.set_ylabel('number of offers with \"x\" words', fontsize = 10)\n    ay.tick_params(labelsize = 10)\n\n# %% [code]\ncat_encoder = LabelEncoder()\n\nfor col in cat_features:\n    dataset[col + '_encode'] = cat_encoder.fit_transform(dataset[col])\n\ndataset['department_encode'] = cat_encoder.fit_transform(dataset['department'])\nprint(dataset.groupby('department_encode').sum())\n\n# %% [code]\n\n\nreal_dataset = dataset[dataset['fraudulent'] == 0].copy()\nfake_dataset = dataset[dataset['fraudulent'] == 1].copy()\n\nreal_sampled_dataset = real_dataset.sample(n = 3000, random_state = 42)\n\nfinal_dataset = pd.concat([real_sampled_dataset, fake_dataset], axis=0)\n\n\nseed_state = 315\nrandom_state = 42\n\n\n\nreal_dataset = final_dataset[final_dataset['fraudulent']==0]\nfake_dataset = final_dataset[final_dataset['fraudulent']==1]\n\ny_real = real_dataset['fraudulent'].copy()\nx_real = real_dataset.drop(['fraudulent'], axis=1)\n\ny_fake = fake_dataset['fraudulent'].copy()\nx_fake = fake_dataset.drop(['fraudulent'], axis=1)\n\nx = pd.concat([x_real, x_fake])\ny = pd.concat([y_real, y_fake])\n\n\n\nx_real_tv, x_real_test, y_real_tv, y_real_test = train_test_split(x_real, y_real, test_size=0.3, random_state=seed_state)\nx_real_train, x_real_val, y_real_train, y_real_val = train_test_split(x_real_tv, y_real_tv, test_size=0.2, random_state=seed_state)\n\nx_fake_tv, x_fake_test, y_fake_tv, y_fake_test = train_test_split(x_fake, y_fake, test_size=0.3, random_state=seed_state)\nx_fake_train, x_fake_val, y_fake_train, y_fake_val = train_test_split(x_fake_tv, y_fake_tv, test_size=0.2, random_state=seed_state)\n\nx_train = pd.concat([x_real_train, x_fake_train])\ny_train = pd.concat([y_real_train, y_fake_train])\n\nx_val = pd.concat([x_real_val, x_fake_val])\ny_val = pd.concat([y_real_val, y_fake_val])\n\nx_test = pd.concat([x_real_test, x_fake_test])\ny_test = pd.concat([y_real_test, y_fake_test])\n\n\nx_train_text = x_train['text'].copy()\nx_val_text = x_val['text'].copy()\nx_test_text = x_test['text'].copy()\n\nrf_features = cat_features_encode + bool_features\n\nx_train_rf = x_train[rf_features].copy()\nx_val_rf = x_train[rf_features].copy()\nx_test_rf = x_train[rf_features].copy()\n\nx_train_cat = x_train[cat_features_encode].copy()\nx_val_cat = x_val[cat_features_encode].copy()\nx_test_cat = x_test[cat_features_encode].copy()\n\nx_train_bool = x_train[bool_features].copy()\nx_val_bool = x_val[bool_features].copy()\nx_test_bool = x_test[bool_features].copy()\n\n#train_text , test_text ,train_category , test_category = train_test_split(dataset[text_features], dataset.fraudulent , test_size = 0.2 , random_state = 0)\n\n# %% [code]\nfor col in text_features:\n    dataset['text'] += dataset[col] + ' ' \n\n# %% [code]\n\n\n# %% [code]\n\"\"\" TF-IDF para analizar la tratar los datos de texto\"\"\"\nvectorizer = TfidfVectorizer(min_df=0,max_df=1,use_idf=True,ngram_range=(1,3)) \n\nfor n in dataset.index:\n       \n    train_vectors = vectorizer.fit_transform(x_train_text)\n    feature_names = vectorizer.get_feature_names()\n    dense = train_vectors.todense()\n    denselist = dense.tolist()\n    dat = pd.DataFrame(denselist, columns=feature_names)\ntest_vectors = vectorizer.transform(x_test_text)\n\nprint('Tfidf_train:',train_vectors.shape)\nprint('Tfidf_test:',test_vectors.shape)\n\n# %% [code]\nmnb = MultinomialNB()\ntfidf = mnb.fit(train_vectors,y_train)\nprint(tfidf)\nmnb_predict = mnb.predict(test_vectors)\nf1_score(y_test,mnb_predict, average = 'weighted')\nprint('score: ', mnb_score)\n\nmatriz(y_test, mnb_predict.round(), 'Confusion Matrix: Text MultinomialNB')\n#mnb_tfidf_report = classification_report(test_category,mnbpredict,target_names = ['0','1'])\n\n\n# %% [code]\ndef matriz(y_valid, predict, title):\n    i = predict.astype(int)\n    cm = confusion_matrix(y_valid, i, labels = np.unique(y_valid))\n    suma = np.sum(cm, axis = 1,keepdims = True)\n    perc = cm / suma.astype(float) * 100\n    annot = np.empty_like(cm).astype(str)\n    rows, cols = cm.shape\n    for row in range(rows):\n        for col in range(cols):\n            c = cm[row, col]\n            p = perc[row, col]\n            if row == col:\n                s = suma[row]\n                annot[row, col] = '%.1f%%\\n%d/%d' % (p, c, s)\n            elif c == 0:\n                annot[row, col] = ''\n            else:\n                annot[row, col] = '%.1f%%\\n%d' % (p, c)\n        \n    cm = pd.DataFrame(cm, index=np.unique(y_valid), columns=np.unique(y_valid))\n    cm.index.name = 'Real values'\n    cm.columns.name = 'Predicted values'\n    fig, ax = plt.subplots(figsize = (14,14))\n    plt.title(title)\n    sns.heatmap(cm, cmap= \"YlGnBu\", annot=annot, fmt='', ax = ax)\n\n# %% [code]\n\nrf_cat = RandomForestClassifier()\n\n#cat_x_train, cat_x_val, cat_y_train, cat_y_val = train_test_split(dataset[cat_features], y, random_state = 42)\n                                                                 \n#bool_x_train, bool_x_val, bool_y_train, bool_y_val = train_test_split(dataset[bool_features], y, random_state= 1)\n#text_x_train, text_x_val, text_y_train, text_y_val = train_test_split(dataset[text_features], y, random_state = 1)\nprint(x_train_rf)\nprint(y_train)   \n\nrf_cat.fit(x_train_cat, y_train)\npredicted_val_cat = rf_cat.predict(x_val_cat)\npredicted_test_cat = rf_cat.predict(x_test_cat)\n\n\nf1_score(y_val, predicted_val_cat.round(), average = 'macro')\nmatriz(y_val, predicted_val_cat.round(), 'Confusion Matrix: categorical Random Forest Validation')\n\n\nf1_score(y_test, predicted_test_cat.round(), average = 'macro')\nmatriz(y_test, predicted_test_cat.round(), 'Confusion Matrix: categorical Random Forest')\n\n\n\n# %% [code]\nrf_bool = RandomForestClassifier()\n\n#cat_x_train, cat_x_val, cat_y_train, cat_y_val = train_test_split(dataset[cat_features], y, random_state = 42)\n                                                                 \n#bool_x_train, bool_x_val, bool_y_train, bool_y_val = train_test_split(dataset[bool_features], y, random_state= 1)\n#text_x_train, text_x_val, text_y_train, text_y_val = train_test_split(dataset[text_features], y, random_state = 1)\nprint(x_train_rf)\nprint(y_train)   \n\nrf_bool.fit(x_train_bool, y_train)\npredicted_val_bool = rf_bool.predict(x_val_bool)\npredicted_test_bool = rf_bool.predict(x_test_bool)\n\nf1_score(y_val, predicted_val_bool.round(), average = 'macro')\nmatriz(y_val, predicted_val_bool.round(), 'Confusion Matrix: boolean Random Forest Validation')\n\nf1_score(y_test,predicted_test_bool.round(), average = 'macro')\nmatriz(y_test, predicted_test_bool.round(), 'Confusion Matrix: boolean Random Forest Test')\n\n# %% [code]\nrf_sal = RandomForestClassifier()\n\n#cat_x_train, cat_x_val, cat_y_train, cat_y_val = train_test_split(dataset[cat_features], y, random_state = 42)\n                                                                 \n#bool_x_train, bool_x_val, bool_y_train, bool_y_val = train_test_split(dataset[bool_features], y, random_state= 1)\n#text_x_train, text_x_val, text_y_train, text_y_val = train_test_split(dataset[text_features], y, random_state = 1)\n \n\nsal_features = ['salary_min', 'salary_max', 'department_encode']\n\n\nx_train_sal = x_train[sal_features].copy()\nx_val_sal = x_val[sal_features].copy()\nx_test_sal = x_test[sal_features].copy()\n\nrf_sal.fit(x_train_sal, y_train)\n\npredicted_val_sal = rf_sal.predict(x_val_sal)\npredicted_test_sal = rf_sal.predict(x_test_sal)\n\nf1_score(y_val, predicted_val_sal.round(), average = 'macro')\nmatriz(y_val, predicted_val_sal.round(), 'Confusion Matrix: categorical Random Forest validation')\n\nf1_score(y_test, predicted_test_sal.round(), average = 'macro')\nmatriz(y_test, predicted_test_sal.round(), 'Confusion Matrix: categorical Random Forest test')\n\n# %% [code]\nagg_val = pd.DataFrame()\nagg_test = pd.DataFrame()\nagg_val['cat_predictions_val'] = predicted_val_cat\nagg_test['cat_predictions_test'] = predicted_test_cat\nagg_val['bool_predictions_val'] = predicted_val_bool\nagg_test['bool_predictions_test'] = predicted_test_bool\nagg_val['sal_predictions_val'] = predicted_val_sal\nagg_test['sal_predictions_test'] = predicted_test_sal\n\nprint(agg_val)\nprint(agg_test)\n\n# %% [code]\nlr = LogisticRegression(C=0.1, solver='lbfgs', max_iter=2000, verbose=0, n_jobs=-1)\nlr.fit(agg_val, y_val)\n\npredictions = lr.predict(agg_test)\n\nf1_score(y_test, predictions, average = 'macro')\nmatriz(y_test, predictions, 'Confusion Matrix: Aggregate Model Final Predictions ')\n\n# %% [code]\n\n\n# Variables del csv que parecen tener mas relacion con las ofertas fraudulentas: Required_education = high school, has_company_logo = 0\nplt.figure(figsize=(20,5))\n#sns.lineplot(data = dataset)\n#sns.barplot(x=x_train.has_company_logo, y=y_train)\n# Create KNeighbors classifier object model\nmodel = KNeighborsClassifier(n_neighbors=6) # default value for n_neighbors is 5\n\n# Train the model using the training sets and check score\n#model.fit(x_train, y_train)\n#x_test=x_train\n#Predict Output\n#predicted= model.predict(x_test)\n\n#sns.lineplot(data = dataset)\n\n# %% [code]\n","execution_count":0,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}